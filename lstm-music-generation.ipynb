{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-29T01:57:31.836636Z","iopub.execute_input":"2022-07-29T01:57:31.837085Z","iopub.status.idle":"2022-07-29T01:57:31.899807Z","shell.execute_reply.started":"2022-07-29T01:57:31.837004Z","shell.execute_reply":"2022-07-29T01:57:31.898813Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2022-07-27T09:18:15.647643Z","iopub.execute_input":"2022-07-27T09:18:15.648349Z","iopub.status.idle":"2022-07-27T09:18:26.916282Z","shell.execute_reply.started":"2022-07-27T09:18:15.648298Z","shell.execute_reply":"2022-07-27T09:18:26.915155Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install music21\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T01:57:52.915567Z","iopub.execute_input":"2022-07-29T01:57:52.915943Z","iopub.status.idle":"2022-07-29T01:58:11.460168Z","shell.execute_reply.started":"2022-07-29T01:57:52.915912Z","shell.execute_reply":"2022-07-29T01:58:11.459041Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import glob\nimport pickle\nimport numpy\nfrom music21 import converter, instrument, note, chord\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm \nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-07-29T01:58:59.869511Z","iopub.execute_input":"2022-07-29T01:58:59.869916Z","iopub.status.idle":"2022-07-29T01:58:59.876035Z","shell.execute_reply.started":"2022-07-29T01:58:59.869882Z","shell.execute_reply":"2022-07-29T01:58:59.874664Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_notes():\n    notes = []\n    for file in glob.glob(\"/kaggle/input/music-data/*.mid\"):\n        midi = converter.parse(file)\n        #notes_to_parse = None\n\n        try: # file has instrument parts\n            s2 = instrument.partitionByInstrument(midi)\n            notes_to_parse = s2.parts[0].recurse() \n        except: # file has notes in a flat structure\n            #print(2)\n            notes_to_parse = midi.flat.notes\n\n        for element in notes_to_parse:\n            if isinstance(element, note.Note):\n                notes.append(str(element.pitch))\n            elif isinstance(element, chord.Chord):\n                notes.append('.'.join(str(n) for n in element.normalOrder))\n\n    with open('/kaggle/working/notes', 'wb') as filepath:\n        pickle.dump(notes, filepath)\n\n    return notes","metadata":{"execution":{"iopub.status.busy":"2022-07-29T02:02:54.751100Z","iopub.execute_input":"2022-07-29T02:02:54.752099Z","iopub.status.idle":"2022-07-29T02:02:54.761933Z","shell.execute_reply.started":"2022-07-29T02:02:54.752059Z","shell.execute_reply":"2022-07-29T02:02:54.760904Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_notes():\n    notes = []\n    for file in glob.glob(\"/kaggle/input/music-data/*.mid\"):\n        midi = converter.parse(file)\n        #notes_to_parse = None\n\n        try: # file has instrument parts\n            s2 = instrument.partitionByInstrument(midi)\n            notes_to_parse = s2.parts[0].recurse() \n        except: # file has notes in a flat structure\n            #print(2)\n            notes_to_parse = midi.flat.notes\n\n        for element in notes_to_parse:\n            if isinstance(element, note.Note):\n                notes.append(str(element.pitch))\n            elif isinstance(element, chord.Chord):\n                notes.append('.'.join(str(n) for n in element.normalOrder))\n\n    with open('/kaggle/working/notes', 'wb') as filepath:\n        pickle.dump(notes, filepath)\n\n    return notes","metadata":{"execution":{"iopub.status.busy":"2022-07-29T02:04:00.302398Z","iopub.execute_input":"2022-07-29T02:04:00.302748Z","iopub.status.idle":"2022-07-29T02:04:00.310842Z","shell.execute_reply.started":"2022-07-29T02:04:00.302719Z","shell.execute_reply":"2022-07-29T02:04:00.309880Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"notes=get_notes()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T02:04:00.541086Z","iopub.execute_input":"2022-07-29T02:04:00.541738Z","iopub.status.idle":"2022-07-29T02:04:05.176289Z","shell.execute_reply.started":"2022-07-29T02:04:00.541702Z","shell.execute_reply":"2022-07-29T02:04:05.174589Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"n_vocab = len(set(notes))","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:27:38.193671Z","iopub.execute_input":"2022-07-28T10:27:38.194664Z","iopub.status.idle":"2022-07-28T10:27:38.203323Z","shell.execute_reply.started":"2022-07-28T10:27:38.194615Z","shell.execute_reply":"2022-07-28T10:27:38.201970Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!pip install np_utils","metadata":{"execution":{"iopub.status.busy":"2022-07-27T14:24:20.996138Z","iopub.execute_input":"2022-07-27T14:24:20.996675Z","iopub.status.idle":"2022-07-27T14:24:33.466210Z","shell.execute_reply.started":"2022-07-27T14:24:20.996631Z","shell.execute_reply":"2022-07-27T14:24:33.465035Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#import np_utils\nfrom tensorflow.keras.utils import to_categorical\ndef prepare_sequences(notes, n_vocab):\n    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n    sequence_length = 100\n\n    # get all pitch names\n    pitchnames = sorted(set(item for item in notes))\n\n     # create a dictionary to map pitches to integers\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n\n    network_input = []\n    network_output = []\n\n    # create input sequences and the corresponding outputs\n    for i in range(0, len(notes) - sequence_length, 1):\n        sequence_in, sequence_out = notes[i:i + sequence_length], notes[i + sequence_length]\n        \n        net_in_lst=[]\n        for char in sequence_in:\n            temp=note_to_int[char]\n            net_in_lst.append(temp)\n        network_input.append(net_in_lst)\n        \n        #network_input.append([note_to_int[char] for char in sequence_in])\n        \n        net_out = note_to_int[sequence_out]\n        network_output.append(net_out)\n\n    n_patterns = len(network_input)\n\n    # reshape the input into a format compatible with LSTM layers\n    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n    # normalize input\n    network_input = network_input / float(n_vocab)\n\n    #network_output = np_utils.to_categorical(network_output)\n    network_output = to_categorical(network_output)\n\n    return (network_input, network_output)\n\nnetwork_input, network_output = prepare_sequences(notes, n_vocab)\n\ndef create_network(network_input, n_vocab):\n    \"\"\" create the structure of the neural network \"\"\"\n    model = Sequential()\n    model.add(LSTM(\n        512,\n        input_shape=(network_input.shape[1], network_input.shape[2]),\n        recurrent_dropout=0.3,\n        return_sequences=True\n    ))\n    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n    model.add(LSTM(512))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(256))\n    model.add(BatchNorm())\n    model.add(Activation('relu'))\n    #model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(BatchNorm())\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n    return model\n\nmodel=create_network(network_input, n_vocab)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:27:43.583261Z","iopub.execute_input":"2022-07-28T10:27:43.583716Z","iopub.status.idle":"2022-07-28T10:27:47.923460Z","shell.execute_reply.started":"2022-07-28T10:27:43.583682Z","shell.execute_reply":"2022-07-28T10:27:47.922495Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\ncheckpoint = ModelCheckpoint(\n    filepath,\n    monitor='loss',\n    verbose=0,\n    save_best_only=True,\n    mode='min'\n)\ncallbacks_list = [checkpoint]\n\nmodel.load_weights('../input/weightnew/weights-improvement-42-0.2623-bigger.hdf5')\n#model.fit(network_input, network_output, epochs=200, batch_size=128, callbacks=callbacks_list, workers=8,use_multiprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:28:25.335732Z","iopub.execute_input":"2022-07-28T10:28:25.336313Z","iopub.status.idle":"2022-07-28T10:28:25.847890Z","shell.execute_reply.started":"2022-07-28T10:28:25.336271Z","shell.execute_reply":"2022-07-28T10:28:25.846964Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def prepare_sequences(notes, pitchnames, n_vocab):\n    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n    # map between notes and integers and back\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n\n    sequence_length = 100\n    network_input = []\n    output = []\n    for i in range(0, len(notes) - sequence_length, 1):\n        sequence_in = notes[i:i + sequence_length]\n        sequence_out = notes[i + sequence_length]\n        network_input.append([note_to_int[char] for char in sequence_in])\n        output.append(note_to_int[sequence_out])\n\n    n_patterns = len(network_input)\n\n    # reshape the input into a format compatible with LSTM layers\n    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n    # normalize input\n    normalized_input = normalized_input / float(n_vocab)\n\n    return (network_input, normalized_input)\n\ndef create_network(network_input, n_vocab):\n    \"\"\" create the structure of the neural network \"\"\"\n    model = Sequential()\n    model.add(LSTM(\n        512,\n        input_shape=(network_input.shape[1], network_input.shape[2]),\n        recurrent_dropout=0.3,\n        return_sequences=True\n    ))\n    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n    model.add(LSTM(512))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n    # Load the weights to each node\n    model.load_weights('weights.hdf5')\n\n    return model\n\ndef generate_notes(model, network_input, pitchnames, n_vocab):\n    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n    # pick a random sequence from the input as a starting point for the prediction\n    start = numpy.random.randint(0, len(network_input)-1)\n\n    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n\n    pattern = network_input[start]\n    prediction_output = []\n\n    # generate 500 notes\n    for note_index in range(500):\n        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n        prediction_input = prediction_input / float(n_vocab)\n\n        prediction = model.predict(prediction_input, verbose=0)\n\n        index = numpy.argmax(prediction)\n        result = int_to_note[index]\n        prediction_output.append(result)\n\n        pattern.append(index)\n        pattern = pattern[1:len(pattern)]\n\n    return prediction_output\n\ndef create_midi(prediction_output):\n    \"\"\" convert the output from the prediction to notes and create a midi file\n        from the notes \"\"\"\n    offset = 0\n    output_notes = []\n\n    # create note and chord objects based on the values generated by the model\n    for pattern in prediction_output:\n        # pattern is a chord\n        if ('.' in pattern) or pattern.isdigit():\n            notes_in_chord = pattern.split('.')\n            notes = []\n            for current_note in notes_in_chord:\n                new_note = note.Note(int(current_note))\n                new_note.storedInstrument = instrument.Piano()\n                notes.append(new_note)\n            new_chord = chord.Chord(notes)\n            new_chord.offset = offset\n            output_notes.append(new_chord)\n        # pattern is a note\n        else:\n            new_note = note.Note(pattern)\n            new_note.offset = offset\n            new_note.storedInstrument = instrument.Piano()\n            output_notes.append(new_note)\n\n        # increase offset each iteration so that notes do not stack\n        offset += 0.5\n\n    midi_stream = stream.Stream(output_notes)\n\n    midi_stream.write('midi', fp='test_output.mid')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:28:28.396794Z","iopub.execute_input":"2022-07-28T10:28:28.397233Z","iopub.status.idle":"2022-07-28T10:28:28.686847Z","shell.execute_reply.started":"2022-07-28T10:28:28.397201Z","shell.execute_reply":"2022-07-28T10:28:28.685464Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from music21 import instrument, note, stream, chord\nwith open('/kaggle/working/notes', 'rb') as filepath:\n        notes = pickle.load(filepath)\n\n# Get all pitch names\npitchnames = sorted(set(item for item in notes))\n# Get all pitch names\nn_vocab = len(set(notes))\n\nnetwork_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n#model = create_network(normalized_input, n_vocab)\nprediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\ncreate_midi(prediction_output)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:19:38.591701Z","iopub.execute_input":"2022-07-28T11:19:38.592074Z","iopub.status.idle":"2022-07-28T11:20:24.308559Z","shell.execute_reply.started":"2022-07-28T11:19:38.592045Z","shell.execute_reply":"2022-07-28T11:20:24.307552Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}